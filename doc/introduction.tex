% !TeX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%																				%%
%% File name: 		introduction.tex											%%
%% Project name:	Applications in Deep Learning								%%
%% Type of work:	Advanced Seminar											%%
%% Author:			Hannes Bohnengel											%%
%% Mentor:			Debayan Roy													%%
%% Date:			25 May 2017													%%
%% University:		Technical University of Munich								%%
%% Comments:		Created in texstudio with tab width = 4						%%
%%																				%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:introduction}

Virtual personal assistants (\acsu{VPA}) like Siri, Cortana or Google Now start having a huge impact on the way of interacting with electronic devices like smartphones or notebooks. Up to now the \acp{VPA} help only with rather simple tasks like search queries, starting phone calls or setting a clock, but according to a recent survey from the IT research firm Gartner~\cite{gartner:assistants}, this will change in the near future. With the Facebook Messenger it is already possible to make purchases or to order an Uber car and new use cases are expected soon. The survey also states, that through the vast increase of devices in the scope of the \ac{IoT} the way of interacting with machines will go towards minimal or zero touch. Instead of interacting through common touch-displays or buttons, the user simply speaks to the device, like to another person. To enable this, both \ac{ASR} and speech synthesis are essential technologies.

In this paper I will only focus on the speech synthesis part. A widley spread technique to synthesize human speech from a given text or from linguistic descriptions is \ac{SPSS}; also referred to as \ac{SPSG} \cite{ling:deep}. This technique is based on the usage of \acp{HMM}. Zen \textsl{et al.} \cite{zen:statistical} show that it has several advantages over its predecessor, the concatenative speech synthesis, for example the flexibility in changing voice characteristics and a smaller memory footprint. However the quality of the generated speech still has potential for improvement. Due to over-smoothing the voice sounds muffled in comparison to natural speech.

This is where recent achievements in deep learning come in. Deep learning is usually referred to as a class of machine learning techniques that achieve tasks like feature extraction or pattern analysis by using many connected layers of non-linear information processing \cite{ling:deep, li:survey}. Since 2006 advances in the training algorithms of \acp{DNN} have enabled the field of deep learning applications to emerge \cite{boros:robust}. Most machine learning models until then had used shallow structures, like for example \acp{HMM}, \acp{GMM}, \acp{CRF} or \acp{SVM}. In these structures only one layer is responsible for generating features out of the raw input signals. While achieving quite good results with rather simple problems, they reach their limit when it comes to more complex tasks like processing human language or natural images \cite{li:survey}.

In the tutorial survey \cite{li:survey} the author states four different approaches to improve the speech synthesis models through deep learning models. Three of them are dealing with \ac{SPSS}:

\textcolor{ACMRed}{\bfseries Remark: Reformulate these points !!!}

\begin{enumerate}[leftmargin=16pt]
	\parskip0.5em
	\item Replacement of the Gausian Models by generative deep learning models (Modeling Spectral Envelopes Using Restricted Boltzmann Machines and Deep Belief Networks for Statistical Parametric Speech Synthesis [XXX])
	\item Representation of joint-distribution of linguistic and acoustic features by generative DBM (Multi-Distribution Deep Belief Network for Speech Synthesis [XXX])
	\item Discriminative model of the DNN to represent the conditional distribution of the acoustic features given the linguistic features (Statistical parametric speech synthesis using deep neural networks \cite{zen:deepstatistical})
\end{enumerate}

\textcolor{ACMRed}{\bfseries Remark: Write something about speech synthesis on embedded devices}

\vspace{1em}

The remaining paper is structured as follows: Section~\ref{sec:speech} first states the motivation, why speech synthesis is a useful technology. Then it describes the conventional approach without deep learning models for speech synthesis and gives an overview of advantages and drawbacks of the used models and techniques. This is followed by a brief explanation of the probably most common used technique \ac{SPSS}, where the paper \cite{zen:statistical} has been chosen as commonly cited reference. Finally two possibilities how \ac{SPSS} can be improved by deploying deep learning models are characterized, wherefore the papers \cite{zen:deepstatistical, hashimoto:effect} are reviewed. In Section~\ref{sec:embeddedspeech} the motivation, why speech synthesis is important on embedded or mobile devices is given followed by two examples on how speech synthesis can be implemented on an embedded system, once without \cite{toth:optimizing} and once with deep learning models \cite{boros:robust}. Finally Section~\ref{sec:conclusion} summarizes the essential points of this paper and gives some future directions.


\vspace{3em}


\textbf{\Large Remarks and notes starting here:}\\


\textbf{Open points:}

\begin{itemize}[leftmargin=10pt]
	\item Improvements of deep learning in speech synthesis also about voice quality. Does that make sense in this context?
	\item Where the focus of this paper should be (deep learning / speech synthesis / embedded devices)? Most papers are available for:
	\begin{itemize}
		\item deep learning <---> speech synthesis
		\item deep learning <---> embedded devices
	\end{itemize}
	\item Where to go into detail? Suggestion: One way of improving speech synthesis with deep learning.
	\item Core paper on \ac{SPSS} \cite{zen:statistical} available in two versions (4 and 23 pages). Which one to use as core paper?
	\item Connection between the improvements of deep learning on speech synthesis (Section) and the implementation of speech synthesis with/without deep learning?
\end{itemize}

\iffalse
\begin{enumerate}[leftmargin=16pt]
	\item \textcolor{black!40}{Why speech synthesis is important? What are its applications?}
	\item \textcolor{black!40}{What are the conventional techniques of speech synthesis? What are the drawbacks of such techniques?}
	\item \textcolor{black!40}{What is deep learning? What improvements do deep learning algorithms bring?}
	\item How some algorithms are modified to suit speech synthesis?
	\item Why is it important to implement speech synthesis on embedded platform?
	\item An example of how speech synthesis can be implemented on embedded platform without deep learning.
	\item How the 3 can be combined?
	\item Future works.
\end{enumerate}
\fi

\vspace{1em}

\textbf{These are the core papers (the red colored):}
\begin{enumerate}[leftmargin=16pt]
	\item \textbf{Conventional \ac{SPSS}}
	\begin{itemize}[leftmargin=10pt]
		\item \textcolor{ACMRed}{Statistical parametric speech synthesis} \cite{zen:statistical}\\
		The most cited paper for \ac{SPSS}. Two versions available, one with 4 pages (IEEE Xplore, 2007) and one with 23 pages ()\cite{zen:statistical}, 2009 , No access over ScienceDirect --> PDF from \url{http://mlsp.cs.cmu.edu/courses/fall2012/lectures/spss_specom.pdf}).
	\end{itemize}
	\vspace{1em}
	\item \textbf{\ac{SPSS} with deep learning in general}
	\begin{itemize}[leftmargin=10pt]
		\item \textcolor{ACMRed}{Statistical parametric speech synthesis using deep neural networks} \cite{zen:deepstatistical}\\
		\textit{"The relationship between input texts and their acoustic realizations is modeled by a DNN. The use of the DNN can address some limitations of the conventional approach. (...) The objective evaluation showed that the use of a deep architecture improved the performance of the neural network-based system for predicting spectral and excitation parameters. (..) One of the advantages of the HMM-based system over the DNN-based one is the reduced computational cost."}
		\item \textcolor{ACMRed}{The effect of neural networks in statistical parametric speech synthesis} \cite{hashimoto:effect}\\
		\textit{"This paper investigates how to use neural networks in statistical parametric speech synthesis. (...) In this paper, the effect of DNNs for each component is investigated by comparing DNNs with generative models. Experimental results show that the use of a DNN as acoustic models is effective and the parameter generation combined with a DNN improves the naturalness of synthesized speech."}
		\item \textcolor{black!40}{Deep neural networks employing Multi-Task Learning and stacked bottleneck features for speech synthesis \cite{wu:deep}}
		\item \textcolor{black!40}{Efficient deep neural networks for speech synthesis using bottleneck features \cite{joo:efficient}}
		\item \textcolor{black!40}{On the training aspects of Deep Neural Network (DNN) for parametric TTS synthesis \cite{qian:training}}
		\item \textcolor{black!40}{TTS synthesis with bidirectional LSTM based recurrent neural networks \cite{fan:tts}}
	\end{itemize}
	\vspace{1em}
	\item \textbf{Speech Synthesis WITHOUT DL on Emb. Systems}
	\begin{itemize}[leftmargin=10pt]
		\item \textcolor{black!40}{Efficient memory compression in deep neural networks using coarse-grain sparsification for speech applications \cite{kadetotad:efficient}}
		\item \textcolor{black!40}{Speeding up deep neural networks for speech recognition on ARM Cortex-A series processors \cite{xing:speeding}}
		\item \textcolor{ACMRed}{Optimizing HMM Speech Synthesis for Low-Resource Devices} \cite{toth:optimizing}\\
		Chosen, because \ac{HMM}-based synthesis is part of \ac{SPSS}. \textit{"Several optimization steps, e.g., changing HMM parameters, applying performance-specific programming methods, are analyzed on three different smartphones in terms of speed, footprint size, and	subjective speech quality. The goal is to approach real-time functionality while keeping the speech quality as high as possible"}
		\item \textcolor{black!40}{Some Aspects of HMM Speech Synthesis Optimization on Mobile Devices \cite{toth:aspects}}
	\end{itemize}
	\vspace{1em}
	\item \textbf{Speech Synthesis WITH DL on Emb. Systems}
	\begin{itemize}[leftmargin=10pt]
		\item \textcolor{ACMRed}{Robust Deep-learning Models for Text-to-speech Synthesis Support on Embedded Devices} \cite{boros:robust}
	\end{itemize}
\end{enumerate}

\vspace{1em}

\textbf{These are interesting references:}
\vspace{1em}
\begin{itemize}[leftmargin=10pt]
	\item Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends \cite{ling:deep}
	\item A tutorial survey of architectures, algorithms, and applications for deep learning \cite{li:survey}
\end{itemize}

%\newpage
\clearpage