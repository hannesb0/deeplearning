% !TeX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%																				%%
%% File name: 		introduction.tex											%%
%% Project name:	Applications in Deep Learning								%%
%% Type of work:	Advanced Seminar											%%
%% Author:			Hannes Bohnengel											%%
%% Mentor:			Debayan Roy													%%
%% Date:			23 May 2017													%%
%% University:		Technical University of Munich								%%
%% Comments:		Created in texstudio with tab width = 4						%%
%%																				%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Introduction}

Virtual personal assistants (\acsu{VPA}) like Siri, Cortana or Google Now start having a huge impact on the way of interacting with electronic devices like smartphones or notebooks. Up to now the \acp{VPA} help only with rather simple tasks like search queries, starting phone calls or setting a clock, but according to a recent survey from the IT research firm Gartner~\cite{gartner:assistants}, this will change in the near future. With the Facebook Messenger it is already possible to make purchases or to order a Uber car and here new use cases are expected soon. The survey also states, that through the vastly increase of devices in the scope of the \ac{IoT} the way of interacting with machines will go towards minimal or zero touch. Instead of interacting through common touch-displays or buttons, the user simply speaks to the device, like to another person. To enable this, both \ac{ASR} and speech synthesis are essential technologies.

In this paper I will only focus on the speech synthesis part. A widley spread technique to synthesize human speech from a given text or from linguistic descriptions is \ac{SPSS}; also referred to as \ac{SPSG} \cite{ling:deep}. This technique is based on the usage of \acp{HMM}. Zen \textsl{et al.} \cite{zen:statistical} show that it has several advantages over its predecessor, the concatenative speech synthesis, for example the flexibility in changing voice characteristics and a smaller memory footprint. However the quality of the generated speech still has potential for improvement. Due to over-smoothing the voice sounds muffled in comparison to natural speech.

This is where recent achievements in deep learning come in. Deep learning is usually referred to as a class of machine learning techniques that achieve tasks like feature extraction or pattern analysis by using many connected layers of non-linear information processing \cite{ling:deep, li:survey}. Since 2006 

In \cite{li:survey} the author states three different approaches to improve \ac{SPSS} through deep learning models: 

\vspace{1em}

\begin{enumerate}
	\parskip0.5em
	\item Modeling Spectral Envelopes Using Restricted Boltzmann Machines and Deep Belief Networks for Statistical Parametric Speech Synthesis [XXX]
	\item Multi-Distribution Deep Belief Network for Speech Synthesis [XXX]
	\item Statistical parametric speech synthesis using deep neural networks \cite{zen:deepstatistical}
\end{enumerate}

\vspace{1em}

\begin{itemize}
	\item some content of core papers
	\item brief description of following sections (structure of paper)
\end{itemize}

\clearpage

\begin{enumerate}[leftmargin=16pt]
	\item Why speech synthesis is important? What are its applications?
	\item What are the conventional techniques of speech synthesis? What are the drawbacks of such techniques?
	\item What is deep learning? What improvements do deep learning algorithms bring?
	\item How some algorithms are modified to suit speech synthesis?
	\item Why is it important to implement speech synthesis on embedded platform?
	\item An example of how speech synthesis can be implemented on embedded platform without deep learning.
	\item How the 3 can be combined?
	\item Future works.
\end{enumerate}

\vspace{1em}

These are the core papers: 
\begin{itemize}[leftmargin=10pt]
	\item Robust Deep-learning Models for Text-to-speech Synthesis Support on Embedded Devices \cite{boros:robust}
	\item Statistical parametric speech synthesis using deep neural networks \cite{zen:deepstatistical}
	\item Deep neural networks employing Multi-Task Learning and stacked bottleneck features for speech synthesis \cite{wu:deep}
	\item Efficient deep neural networks for speech synthesis using bottleneck features \cite{joo:efficient}
	\item On the training aspects of Deep Neural Network (DNN) for parametric TTS synthesis \cite{qian:training}
	\item TTS synthesis with bidirectional LSTM based recurrent neural networks \cite{fan:tts}
	\item The effect of neural networks in statistical parametric speech synthesis \cite{hashimoto:effect}
	\item Efficient memory compression in deep neural networks using coarse-grain sparsification for speech applications \cite{kadetotad:efficient}
	\item Speeding up deep neural networks for speech recognition on ARM Cortex-A series processors \cite{xing:speeding}
\end{itemize}

\vspace{1em}

These are interesting references:

\begin{itemize}[leftmargin=10pt]
	\item Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends \cite{ling:deep}
	\item A tutorial survey of architectures, algorithms, and applications for deep learning \cite{li:survey}
\end{itemize}

%\newpage
\clearpage