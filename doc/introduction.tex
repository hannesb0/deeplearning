%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%																				%%
%% File name: 		introduction.tex											%%
%% Project name:	Applications in Deep Learning								%%
%% Type of work:	Advanced Seminar											%%
%% Author:			Hannes Bohnengel											%%
%% Mentor:			Debayan Roy													%%
%% Date:			20 May 2017													%%
%% University:		Technical University of Munich								%%
%% Comments:		Created in texstudio with tab width = 4						%%
%%																				%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

The \textit{proceedings} are the records of a conference.\footnote{This is a footnote}  ACM seeks to give these conference by-products a uniform, high-quality appearance.  To do this, ACM has some rigid requirements for the format of the proceedings documents: there is a specified format (balanced double columns), a specified set of fonts (Arial or
Helvetica and Times Roman) in certain specified sizes, a specified live area, centered on the page, specified size of margins, specified column width and gutter size.

These are the core papers: 
\begin{itemize} %%{label}{spacing}
	\item Robust Deep-learning Models for Text-to-speech Synthesis Support on Embedded Devices \cite{boros:robust}
	\item Statistical parametric speech synthesis using deep neural networks \cite{ze:statistical}
	\item Deep neural networks employing Multi-Task Learning and stacked bottleneck features for speech synthesis \cite{wu:deep}
	\item Efficient deep neural networks for speech synthesis using bottleneck features \cite{joo:efficient}
	\item On the training aspects of Deep Neural Network (DNN) for parametric TTS synthesis \cite{qian:training}
	\item TTS synthesis with bidirectional LSTM based recurrent neural networks \cite{fan:tts}
	\item The effect of neural networks in statistical parametric speech synthesis \cite{hashimoto:effect}
	\item Efficient memory compression in deep neural networks using coarse-grain sparsification for speech applications \cite{kadetotad:efficient}
	\item Speeding up deep neural networks for speech recognition on ARM Cortex-A series processors \cite{xing:speeding}
\end{itemize}

These are interesting references:

\begin{itemize} %%{label}{spacing}
	\item Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends \cite{ling:deep}
\end{itemize}
